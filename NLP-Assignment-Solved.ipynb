{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Assignment 1\n",
    "\n",
    "In this assignment we are meant to use the corpus (plain text) to generate N-gram models where n: 2-6. <br>\n",
    "The user should enter number of words (tokens) in the desired sentence, for example 10 words and should enter one word. <br>\n",
    "The output should have 10 words/tokens. We also going to evaluate 8 test samples by human expert (myself or my friend)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Code\n",
    "\n",
    "We start by importing the neccessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from random import choice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the corpus path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'Corpus'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the user is allowed to set the desired n-gram.\n",
    "For testing purposes we sat it to 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n value: 3\n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Enter the value of n for the n-gram model: \"))\n",
    "print('n value:', n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we declare 4 dictionaries that are used to store n-grams, n-grams frequency, n-gram probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_counts = defaultdict(int)\n",
    "n_minus1_gram_counts = defaultdict(int)\n",
    "n_gram_frequency = defaultdict(int)\n",
    "n_gram_probs = defaultdict(dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_file function reads the passed file and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess_text as the name says it preprocess the text, toknize it and remove the non-arabic characters and the punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\s]+', '', text) # Remove all non-Arabic characters\n",
    "    words = nltk.word_tokenize(text) # Tokenize the words\n",
    "    \n",
    "    filtered_words = [word for word in words if word not in string.punctuation and word != \"،\"] # Remove punctuation\n",
    "    \n",
    "    # arabic_stop_words = set(stopwords.words('arabic')) # Here we get the stop words of arabic مثل: هذه, هذا, و\n",
    "    # filtered_words = [word for word in words if word.casefold() not in arabic_stop_words and word.isalpha()] # Here we remove these stop words and numbers\n",
    "    # filtered_words = [word for word in filtered_words if word not in string.punctuation] # Remove punctuation\n",
    "\n",
    "    return filtered_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we loop through the files in the corpus and apply the prevois two functions then store the results in n_gram_counts\n",
    "(💡Note: The whole corpus are being used.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir, _, files in os.walk(root_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            file_path = os.path.join(dir, file)\n",
    "            text = read_file(file_path)\n",
    "            words = preprocess_text(text)\n",
    "            for i in range(len(words) - n + 1):\n",
    "                n_gram = tuple(words[i:i+n])\n",
    "                n_gram_counts[n_gram] += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece of code maps a n-1 gram (i.e. the first n-1 words in a n-gram) to the total count of all n-grams that start with that same n-1 gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_gram, count in n_gram_counts.items():\n",
    "    n_minus1_gram = n_gram[:-1]\n",
    "    n_minus1_gram_counts[n_minus1_gram] += count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get the top 10 most frequent n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent 3-grams:\n",
      "('صلى', 'الله', 'عليه'): 186980\n",
      "('الله', 'عليه', 'وسلم'): 162840\n",
      "('الله', 'صلى', 'الله'): 98126\n",
      "('رسول', 'الله', 'صلى'): 93524\n",
      "('عبد', 'الله', 'بن'): 73723\n",
      "('النبي', 'صلى', 'الله'): 68501\n",
      "('بن', 'عبد', 'الله'): 30801\n",
      "('عبد', 'الرحمن', 'بن'): 21843\n",
      "('رضي', 'الله', 'عنه'): 21212\n",
      "('الله', 'عز', 'وجل'): 20388\n"
     ]
    }
   ],
   "source": [
    "top_n = 10\n",
    "sorted_n_grams = sorted(n_gram_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "print(f\"Top {top_n} most frequent {n}-grams:\")\n",
    "for n_gram, count in sorted_n_grams:\n",
    "    print(f\"{n_gram}: {count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This for loop calculate the probabilities of the n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_gram, count in n_gram_counts.items():\n",
    "    n_minus1_gram = n_gram[:-1]\n",
    "    prob = count / n_minus1_gram_counts[n_minus1_gram]\n",
    "    n_gram_probs[n_minus1_gram][n_gram[-1]] = prob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we print the probabilties, 10 samples of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 probabilities for ('بسم', 'الله'):\n",
      "الرحمن: 0.8827483196415236\n",
      "مجراها: 0.012447099825740602\n",
      "والله: 0.006472491909385114\n",
      "قال: 0.004729897933781429\n",
      "وعلى: 0.003236245954692557\n",
      "الذي: 0.0027383619616629324\n",
      "أرقيك: 0.0027383619616629324\n",
      "خير: 0.0024894199651481204\n",
      "ثم: 0.0022404779686333084\n",
      "فلما: 0.0019915359721184964\n",
      "\n",
      "Top 10 probabilities for ('الله', 'الرحمن'):\n",
      "الرحيم: 0.8947368421052632\n",
      "الرحيم،: 0.09844559585492228\n",
      "الرحيم؟: 0.00218161985274066\n",
      "الرحيم؛: 0.000545404963185165\n",
      "على: 0.0002727024815925825\n",
      "عز: 0.0002727024815925825\n",
      "ص: 0.0002727024815925825\n",
      "حتى: 0.0002727024815925825\n",
      "فجرت: 0.0002727024815925825\n",
      "فلما: 0.0002727024815925825\n",
      "\n",
      "Top 10 probabilities for ('الرحمن', 'الرحيم'):\n",
      "قوله: 0.08283175695041559\n",
      "سورة: 0.052163943823445115\n",
      "من: 0.049011177987962166\n",
      "قال: 0.039839495557466326\n",
      "الحمد: 0.03210088850673545\n",
      "كتاب: 0.02722843221553454\n",
      "هذا: 0.025508741759816565\n",
      "رب: 0.020349670392662653\n",
      "نا: 0.01948982516480367\n",
      "القول: 0.01834336486099169\n",
      "\n",
      "Top 10 probabilities for ('الرحيم', 'الحمد'):\n",
      "لله: 0.9553571428571429\n",
      "لله،: 0.026785714285714284\n",
      "فوصلت: 0.008928571428571428\n",
      "ص: 0.008928571428571428\n",
      "\n",
      "Top 10 probabilities for ('الحمد', 'لله'):\n",
      "الذي: 0.4433923425277892\n",
      "رب: 0.1667352820090572\n",
      "على: 0.03952243721696171\n",
      "بل: 0.019761218608480857\n",
      "حمدا: 0.011527377521613832\n",
      "الذى: 0.01029230135858378\n",
      "الوهوب: 0.009468917249897077\n",
      "وسلام: 0.008645533141210375\n",
      "فاطر: 0.008645533141210375\n",
      "الواحد: 0.007410456978180321\n",
      "\n",
      "Top 10 probabilities for ('لله', 'رب'):\n",
      "العالمين: 0.8060046189376443\n",
      "العالمين،: 0.17090069284064666\n",
      "العلمين: 0.004618937644341801\n",
      "العالمين؛: 0.003464203233256351\n",
      "العزة: 0.003464203233256351\n",
      "كل: 0.0023094688221709007\n",
      "العرش: 0.0011547344110854503\n",
      "العالمين،،: 0.0011547344110854503\n",
      "في: 0.0011547344110854503\n",
      "العالمين؟: 0.0011547344110854503\n",
      "\n",
      "Top 10 probabilities for ('رب', 'العالمين'):\n",
      "قال: 0.07025316455696203\n",
      "وصلى: 0.048734177215189876\n",
      "حدثنا: 0.030379746835443037\n",
      "الفاتحة: 0.022151898734177215\n",
      "يقول: 0.020253164556962026\n",
      "ثم: 0.017721518987341773\n",
      "وصلواته: 0.01708860759493671\n",
      "لا: 0.016455696202531647\n",
      "أم: 0.016455696202531647\n",
      "الرحمن: 0.012658227848101266\n",
      "\n",
      "Top 10 probabilities for ('العالمين', 'الرحمن'):\n",
      "الرحيم: 0.9523809523809523\n",
      "الرحيم،: 0.047619047619047616\n",
      "\n",
      "Top 10 probabilities for ('الرحيم', 'مالك'):\n",
      "يوم: 0.9166666666666666\n",
      "الإمام: 0.08333333333333333\n",
      "\n",
      "Top 10 probabilities for ('مالك', 'يوم'):\n",
      "الدين: 0.8176795580110497\n",
      "الدين،: 0.06077348066298342\n",
      "أحد: 0.011049723756906077\n",
      "يدان: 0.011049723756906077\n",
      "السبت: 0.011049723756906077\n",
      "القيامة،: 0.0055248618784530384\n",
      "قال: 0.0055248618784530384\n",
      "غصبها،: 0.0055248618784530384\n",
      "يستحقها؛: 0.0055248618784530384\n",
      "غصبه،: 0.0055248618784530384\n",
      "\n",
      "Top 10 probabilities for ('يوم', 'الدين'):\n",
      "قال: 0.09821428571428571\n",
      "يوم: 0.05357142857142857\n",
      "حدثنا: 0.04017857142857143\n",
      "يقول: 0.04017857142857143\n",
      "إياك: 0.024553571428571428\n",
      "الفاتحة: 0.024553571428571428\n",
      "أي: 0.024553571428571428\n",
      "يعني: 0.017857142857142856\n",
      "نحن: 0.015625\n",
      "رب: 0.013392857142857142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_counter = 0\n",
    "for n_minus1_gram, prob_dict in n_gram_probs.items():\n",
    "    print(f\"Top 10 probabilities for {n_minus1_gram}:\")\n",
    "    sorted_probs = sorted(prob_dict.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    for next_word, prob in sorted_probs:\n",
    "        print(f\"{next_word}: {prob}\")\n",
    "    print()\n",
    "    temp_counter += 1\n",
    "    if temp_counter > 10:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method predicts the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_n_words(initial_words, num_words):\n",
    "    words = preprocess_text(initial_words)\n",
    "    num_words += n - 1\n",
    "    while len(words) < num_words:\n",
    "        n_minus1_gram = tuple(words[-(n-1):])\n",
    "        if n_minus1_gram not in n_gram_probs:\n",
    "            break\n",
    "        next_word = max(n_gram_probs[n_minus1_gram], key=n_gram_probs[n_minus1_gram].get)\n",
    "        words.append(next_word)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This while loop prompt for the user the required number of initial words + how many words he want.\n",
    "An example is showing in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    initial_words = input(f\"Enter {n-1} initial words (separated by spaces) or 'q' to quit: \")\n",
    "    if initial_words == 'q':\n",
    "        break\n",
    "    num_words = int(input(\"Enter the number of words you want to generate: \"))\n",
    "    prediction = predict_next_n_words(initial_words, num_words)\n",
    "    print(f\"Generated text: {prediction}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated text: السلام عليكم ورحمة الله وبركاته فقال له يا أبا عبد الله بن<br>\n",
    "Generated text: محمد صلى الله عليه وسلم قال من كان في ذلك قال أهل<br>\n",
    "Generated text: محمد صلى الله عليه وسلم قال من كان في ذلك قال أهل<br>\n",
    "Generated text: ابو بكر بن أبي طالب رضي الله عنه قال قال رسول الله<br>\n",
    "Generated text: علي بن أبي طالب رضي الله عنه قال قال رسول الله صلى الله عليه وسلم قال من كان في ذلك قال أهل<br>\n",
    "Generated text: يا غلام أعطه أربعة آلاف درهم قال أبو جعفر يعني بذلك جل<br>\n",
    "Generated text: ابو احمد بن محمد بن عبد الله بن أبي طالب رضي الله<br>\n",
    "Generated text: ابو جعفر محمد بن عبد الله بن أبي طالب رضي الله عنه<br>\n",
    "Generated text: عبد الله بن أبي طالب رضي الله عنه قال قال رسول الله<br>\n",
    "Generated text: عبد الرحمن بن أبي طالب رضي الله عنه قال قال رسول الله<br>\n",
    "Generated text: مالك يوم الدين قال أبو جعفر يعني بذلك جل ثناؤه بقوله ومن<br>\n",
    "Generated text: إياك نعبد وإياك نستعين اهدنا الصراط المستقيم صراط الذين أنعمت عليهم غير"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-complete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
